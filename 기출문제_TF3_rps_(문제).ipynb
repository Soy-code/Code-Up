{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soy-code/Code-Up/blob/master/%EA%B8%B0%EC%B6%9C%EB%AC%B8%EC%A0%9C_TF3_rps_(%EB%AC%B8%EC%A0%9C).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg-hP0itZxmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c2eab53-19f9-44f4-f0d8-a983dd55f67a"
      },
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this test with increasing difficulty from 1-5\n",
        "# Please note that the weight of the grade for the question is relative\n",
        "# to its difficulty. So your Category 1 question will score much less\n",
        "# than your Category 5 question.\n",
        "# ======================================================================\n",
        "#\n",
        "# Computer Vision with CNNs\n",
        "#\n",
        "# For this task you will build a classifier for Rock-Paper-Scissors \n",
        "# based on the rps dataset.\n",
        "#\n",
        "# IMPORTANT: Your final layer should be as shown, do not change the\n",
        "# provided code, or the tests may fail\n",
        "#\n",
        "# IMPORTANT: Images will be tested as 150x150 with 3 bytes of color depth\n",
        "# So ensure that your input layer is designed accordingly, or the tests\n",
        "# may fail. \n",
        "#\n",
        "# NOTE THAT THIS IS UNLABELLED DATA. \n",
        "# You can use the ImageDataGenerator to automatically label it\n",
        "# and we have provided some starter code.\n",
        "\n",
        "# =========== 합격 기준 가이드라인 공유 ============= #\n",
        "# val_loss 기준에 맞춰 주시는 것이 훨씬 더 중요 #\n",
        "# val_loss 보다 조금 높아도 상관없음. (언저리까지 OK) #\n",
        "# =================================================== #\n",
        "# 문제명: Category 3 - rps\n",
        "# val_loss: 0.0871\n",
        "# val_acc: 0.97\n",
        "# =================================================== #\n",
        "# =================================================== #\n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds \n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def solution_model():\n",
        "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\n",
        "    urllib.request.urlretrieve(url, 'rps.zip')\n",
        "    local_zip = 'rps.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/')\n",
        "    zip_ref.close()\n",
        "\n",
        "    TRAINING_DIR = \"tmp/rps/\"\n",
        "    training_datagen = ImageDataGenerator(\n",
        "            rescale =  1. / 255,   # 픽셀값 조절\n",
        "            rotation_range = 40,    # 이미지 회전\n",
        "            width_shift_range = 0.2,   # 가로 방향 이동\n",
        "            height_shift_range = 0.2,    # 세로 방향 이동\n",
        "            shear_range = 0.2,   # 이미지 굴절\n",
        "            zoom_range = 0.2,    # 이미지 확대\n",
        "            horizontal_flip = True,    # 횡 방향으로 이미지 반전\n",
        "            fill_mode = 'nearest',   # 빈 픽셀값에 대하여 값을 채우는 방식\n",
        "            validation_split = 0.2    # --> train데이터 valid데이터 split\n",
        "    )\n",
        "\n",
        "    train_generator = training_datagen.flow_from_directory(\n",
        "        TRAINING_DIR,\n",
        "        batch_size = 32, \n",
        "        target_size = (150, 150),\n",
        "        class_mode = 'categorical',   # 출력층이 sigmoid인 경우에는 binary로 넣어줘야 함 \n",
        "        subset = 'training',\n",
        "    )\n",
        "\n",
        "    validation_generator = training_datagen.flow_from_directory(\n",
        "        TRAINING_DIR,\n",
        "        batch_size = 32, \n",
        "        target_size = (150, 150), \n",
        "        class_mode = 'categorical', \n",
        "        subset = 'validation',   \n",
        "    )\n",
        "\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "            Conv2D(128, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n",
        "            MaxPooling2D(2, 2), \n",
        "            Conv2D(64, (3, 3), activation = 'relu'), \n",
        "            MaxPooling2D(2, 2),\n",
        "            Conv2D(128, (3, 3), activation = 'relu'), \n",
        "            MaxPooling2D(2, 2), \n",
        "            Conv2D(64, (3, 3), activation = 'relu'), \n",
        "            MaxPooling2D(2, 2),\n",
        "            Flatten(), \n",
        "            Dropout(0.3), \n",
        "            Dense(128, activation = 'relu'), \n",
        "            Dropout(0.3),\n",
        "            Dense(64, activation = 'relu'), \n",
        "    # YOUR CODE HERE, BUT END WITH A 3 Neuron Dense, activated by softmax\n",
        "            tf.keras.layers.Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
        "\n",
        "    # 체크포인트 생성\n",
        "    checkpoint_path = 'my_checkpoint_3-rps-1.ckpt'\n",
        "    checkpoint = ModelCheckpoint(filepath = checkpoint_path, \n",
        "                                 save_best_only = True, \n",
        "                                 save_weights_only = True, \n",
        "                                 monitor = 'val_loss', \n",
        "                                 verbose = 1)\n",
        "\n",
        "    # 모델 학습\n",
        "    model.fit(train_generator, \n",
        "              validation_data = (validation_generator), \n",
        "              epochs = 15, \n",
        "              callbacks = [checkpoint])\n",
        "    \n",
        "    # best 모델 로드드\n",
        "    model.load_weights(checkpoint_path)\n",
        "\n",
        "    # 모델 검증\n",
        "    model.evaluate(validation_generator)  # [0.17 0.93]\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Note that you'll need to save your model as a .h5 like this\n",
        "# This .h5 will be uploaded to the testing infrastructure\n",
        "# and a score will be returned to you\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"TF3-rps-1.h5\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2016 images belonging to 3 classes.\n",
            "Found 504 images belonging to 3 classes.\n",
            "Epoch 1/15\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.1009 - acc: 0.3194\n",
            "Epoch 1: val_loss improved from inf to 1.11683, saving model to my_checkpoint_3-rps-1.ckpt\n",
            "63/63 [==============================] - 21s 327ms/step - loss: 1.1009 - acc: 0.3194 - val_loss: 1.1168 - val_acc: 0.3333\n",
            "Epoch 2/15\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.0802 - acc: 0.3993\n",
            "Epoch 2: val_loss improved from 1.11683 to 1.08473, saving model to my_checkpoint_3-rps-1.ckpt\n",
            "63/63 [==============================] - 20s 311ms/step - loss: 1.0802 - acc: 0.3993 - val_loss: 1.0847 - val_acc: 0.3274\n",
            "Epoch 3/15\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.9133 - acc: 0.5957\n",
            "Epoch 3: val_loss improved from 1.08473 to 0.93346, saving model to my_checkpoint_3-rps-1.ckpt\n",
            "63/63 [==============================] - 20s 311ms/step - loss: 0.9133 - acc: 0.5957 - val_loss: 0.9335 - val_acc: 0.4980\n",
            "Epoch 4/15\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.6313 - acc: 0.7346\n",
            "Epoch 4: val_loss improved from 0.93346 to 0.82263, saving model to my_checkpoint_3-rps-1.ckpt\n",
            "63/63 [==============================] - 20s 313ms/step - loss: 0.6313 - acc: 0.7346 - val_loss: 0.8226 - val_acc: 0.5853\n",
            "Epoch 5/15\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.4812 - acc: 0.8056\n",
            "Epoch 5: val_loss improved from 0.82263 to 0.52631, saving model to my_checkpoint_3-rps-1.ckpt\n",
            "63/63 [==============================] - 20s 315ms/step - loss: 0.4812 - acc: 0.8056 - val_loss: 0.5263 - val_acc: 0.7639\n",
            "Epoch 6/15\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2947 - acc: 0.8874\n",
            "Epoch 6: val_loss did not improve from 0.52631\n",
            "63/63 [==============================] - 20s 313ms/step - loss: 0.2947 - acc: 0.8874 - val_loss: 1.2146 - val_acc: 0.5913\n",
            "Epoch 7/15\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3343 - acc: 0.8819\n",
            "Epoch 7: val_loss did not improve from 0.52631\n",
            "63/63 [==============================] - 19s 309ms/step - loss: 0.3343 - acc: 0.8819 - val_loss: 0.7969 - val_acc: 0.5992\n",
            "Epoch 8/15\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2256 - acc: 0.9162\n",
            "Epoch 8: val_loss did not improve from 0.52631\n",
            "63/63 [==============================] - 20s 313ms/step - loss: 0.2256 - acc: 0.9162 - val_loss: 0.6745 - val_acc: 0.6964\n",
            "Epoch 9/15\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2072 - acc: 0.9261\n",
            "Epoch 9: val_loss improved from 0.52631 to 0.49096, saving model to my_checkpoint_3-rps-1.ckpt\n",
            "63/63 [==============================] - 20s 312ms/step - loss: 0.2072 - acc: 0.9261 - val_loss: 0.4910 - val_acc: 0.7917\n",
            "Epoch 10/15\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1623 - acc: 0.9425\n",
            "Epoch 10: val_loss improved from 0.49096 to 0.48609, saving model to my_checkpoint_3-rps-1.ckpt\n",
            "63/63 [==============================] - 20s 320ms/step - loss: 0.1623 - acc: 0.9425 - val_loss: 0.4861 - val_acc: 0.7837\n",
            "Epoch 11/15\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1198 - acc: 0.9583\n",
            "Epoch 11: val_loss improved from 0.48609 to 0.31721, saving model to my_checkpoint_3-rps-1.ckpt\n",
            "63/63 [==============================] - 20s 313ms/step - loss: 0.1198 - acc: 0.9583 - val_loss: 0.3172 - val_acc: 0.8651\n",
            "Epoch 12/15\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1320 - acc: 0.9524\n",
            "Epoch 12: val_loss did not improve from 0.31721\n",
            "63/63 [==============================] - 20s 313ms/step - loss: 0.1320 - acc: 0.9524 - val_loss: 0.3678 - val_acc: 0.8571\n",
            "Epoch 13/15\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1032 - acc: 0.9623\n",
            "Epoch 13: val_loss did not improve from 0.31721\n",
            "63/63 [==============================] - 20s 313ms/step - loss: 0.1032 - acc: 0.9623 - val_loss: 0.3896 - val_acc: 0.8472\n",
            "Epoch 14/15\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1119 - acc: 0.9633\n",
            "Epoch 14: val_loss did not improve from 0.31721\n",
            "63/63 [==============================] - 20s 318ms/step - loss: 0.1119 - acc: 0.9633 - val_loss: 0.5509 - val_acc: 0.8413\n",
            "Epoch 15/15\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1367 - acc: 0.9549\n",
            "Epoch 15: val_loss did not improve from 0.31721\n",
            "63/63 [==============================] - 20s 314ms/step - loss: 0.1367 - acc: 0.9549 - val_loss: 0.4251 - val_acc: 0.8234\n",
            "16/16 [==============================] - 4s 239ms/step - loss: 0.3282 - acc: 0.8750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this test with increasing difficulty from 1-5\n",
        "# Please note that the weight of the grade for the question is relative\n",
        "# to its difficulty. So your Category 1 question will score much less\n",
        "# than your Category 5 question.\n",
        "# ======================================================================\n",
        "#\n",
        "# Computer Vision with CNNs\n",
        "#\n",
        "# For this task you will build a classifier for Rock-Paper-Scissors \n",
        "# based on the rps dataset.\n",
        "#\n",
        "# IMPORTANT: Your final layer should be as shown, do not change the\n",
        "# provided code, or the tests may fail\n",
        "#\n",
        "# IMPORTANT: Images will be tested as 150x150 with 3 bytes of color depth\n",
        "# So ensure that your input layer is designed accordingly, or the tests\n",
        "# may fail. \n",
        "#\n",
        "# NOTE THAT THIS IS UNLABELLED DATA. \n",
        "# You can use the ImageDataGenerator to automatically label it\n",
        "# and we have provided some starter code.\n",
        "\n",
        "# =========== 합격 기준 가이드라인 공유 ============= #\n",
        "# val_loss 기준에 맞춰 주시는 것이 훨씬 더 중요 #\n",
        "# val_loss 보다 조금 높아도 상관없음. (언저리까지 OK) #\n",
        "# =================================================== #\n",
        "# 문제명: Category 3 - rps\n",
        "# val_loss: 0.0871\n",
        "# val_acc: 0.97\n",
        "# =================================================== #\n",
        "# =================================================== #\n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds \n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def solution_model():\n",
        "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\n",
        "    urllib.request.urlretrieve(url, 'rps.zip')\n",
        "    local_zip = 'rps.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/')\n",
        "    zip_ref.close()\n",
        "\n",
        "    TRAINING_DIR = \"tmp/rps/\"\n",
        "    training_datagen = ImageDataGenerator(\n",
        "        rescale =  1. / 255,   # 픽셀값 조절\n",
        "        rotation_range = 30,    # 이미지 회전\n",
        "        width_shift_range = 0.15,   # 가로 방향 이동\n",
        "        height_shift_range = 0.15,    # 세로 방향 이동\n",
        "        shear_range = 0.2,   # 이미지 굴절\n",
        "        zoom_range = 0.2,    # 이미지 확대\n",
        "        horizontal_flip = True,    # 횡 방향으로 이미지 반전\n",
        "        fill_mode = 'nearest',   # 빈 픽셀값에 대하여 값을 채우는 방식\n",
        "        validation_split = 0.2    # --> train데이터 valid데이터 split\n",
        "    )\n",
        "\n",
        "    train_generator = training_datagen.flow_from_directory(\n",
        "        TRAINING_DIR,\n",
        "        batch_size = 32, \n",
        "        target_size = (150, 150),\n",
        "        class_mode = 'categorical',   # 출력층이 sigmoid인 경우에는 binary로 넣어줘야 함 \n",
        "        subset = 'training',\n",
        "    )\n",
        "\n",
        "    validation_generator = training_datagen.flow_from_directory(\n",
        "        TRAINING_DIR,\n",
        "        batch_size = 32, \n",
        "        target_size = (150, 150), \n",
        "        class_mode = 'categorical', \n",
        "        subset = 'validation',   \n",
        "    )\n",
        "\n",
        "    # 모델 정의\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n",
        "        MaxPooling2D(2, 2), \n",
        "        Conv2D(64, (3, 3), activation = 'relu'), \n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(128, (3, 3), activation = 'relu'), \n",
        "        MaxPooling2D(2, 2), \n",
        "        Conv2D(128, (3, 3), activation = 'relu'), \n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(), \n",
        "        Dropout(0.5), \n",
        "        Dense(512, activation = 'relu'), \n",
        "        Dense(3, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    # 모델 생성\n",
        "    # IDG는 자동으로 one hot encoding 해줌. \n",
        "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
        "    # optimizer = 'rmsprop'\n",
        "\n",
        "    # 체크포인트 생성\n",
        "    checkpoint_path = 'my_checkpoint_3-rps-2.ckpt'\n",
        "    checkpoint = ModelCheckpoint(filepath = checkpoint_path, \n",
        "                                 save_best_only = True, \n",
        "                                 save_weights_only = True, \n",
        "                                 monitor = 'val_loss', \n",
        "                                 verbose = 1)\n",
        "\n",
        "    # 모델 학습\n",
        "    model.fit(train_generator, \n",
        "          validation_data = (validation_generator), \n",
        "          epochs = 20, \n",
        "          callbacks = [checkpoint])\n",
        "\n",
        "    # best 모델 로드드\n",
        "    model.load_weights(checkpoint_path)\n",
        "\n",
        "    # 모델 검증\n",
        "    print(model.evaluate(validation_generator))  # [0.16, 0.94]\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Note that you'll need to save your model as a .h5 like this\n",
        "# This .h5 will be uploaded to the testing infrastructure\n",
        "# and a score will be returned to you\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"TF3-rps-2.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9-VwdEI4kY_",
        "outputId": "742d9131-672e-46a7-deae-77c51daca9f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2016 images belonging to 3 classes.\n",
            "Found 504 images belonging to 3 classes.\n",
            "Epoch 1/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.0405 - acc: 0.4658\n",
            "Epoch 1: val_loss improved from inf to 1.03849, saving model to my_checkpoint_3-rps-2.ckpt\n",
            "63/63 [==============================] - 21s 315ms/step - loss: 1.0405 - acc: 0.4658 - val_loss: 1.0385 - val_acc: 0.4464\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.6898 - acc: 0.7183\n",
            "Epoch 2: val_loss improved from 1.03849 to 0.76584, saving model to my_checkpoint_3-rps-2.ckpt\n",
            "63/63 [==============================] - 19s 306ms/step - loss: 0.6898 - acc: 0.7183 - val_loss: 0.7658 - val_acc: 0.6687\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3375 - acc: 0.8735\n",
            "Epoch 3: val_loss improved from 0.76584 to 0.50032, saving model to my_checkpoint_3-rps-2.ckpt\n",
            "63/63 [==============================] - 19s 301ms/step - loss: 0.3375 - acc: 0.8735 - val_loss: 0.5003 - val_acc: 0.8294\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2346 - acc: 0.9182\n",
            "Epoch 4: val_loss did not improve from 0.50032\n",
            "63/63 [==============================] - 19s 305ms/step - loss: 0.2346 - acc: 0.9182 - val_loss: 0.5626 - val_acc: 0.7560\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1603 - acc: 0.9449\n",
            "Epoch 5: val_loss improved from 0.50032 to 0.29917, saving model to my_checkpoint_3-rps-2.ckpt\n",
            "63/63 [==============================] - 19s 307ms/step - loss: 0.1603 - acc: 0.9449 - val_loss: 0.2992 - val_acc: 0.8968\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1101 - acc: 0.9633\n",
            "Epoch 6: val_loss did not improve from 0.29917\n",
            "63/63 [==============================] - 19s 303ms/step - loss: 0.1101 - acc: 0.9633 - val_loss: 0.3363 - val_acc: 0.8710\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1016 - acc: 0.9668\n",
            "Epoch 7: val_loss did not improve from 0.29917\n",
            "63/63 [==============================] - 19s 303ms/step - loss: 0.1016 - acc: 0.9668 - val_loss: 0.3778 - val_acc: 0.8690\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0860 - acc: 0.9752\n",
            "Epoch 8: val_loss did not improve from 0.29917\n",
            "63/63 [==============================] - 19s 303ms/step - loss: 0.0860 - acc: 0.9752 - val_loss: 0.3347 - val_acc: 0.8611\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0565 - acc: 0.9816\n",
            "Epoch 9: val_loss improved from 0.29917 to 0.24050, saving model to my_checkpoint_3-rps-2.ckpt\n",
            "63/63 [==============================] - 19s 302ms/step - loss: 0.0565 - acc: 0.9816 - val_loss: 0.2405 - val_acc: 0.9266\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0509 - acc: 0.9777\n",
            "Epoch 10: val_loss improved from 0.24050 to 0.23471, saving model to my_checkpoint_3-rps-2.ckpt\n",
            "63/63 [==============================] - 19s 305ms/step - loss: 0.0509 - acc: 0.9777 - val_loss: 0.2347 - val_acc: 0.9286\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0597 - acc: 0.9816\n",
            "Epoch 11: val_loss did not improve from 0.23471\n",
            "63/63 [==============================] - 19s 304ms/step - loss: 0.0597 - acc: 0.9816 - val_loss: 0.2443 - val_acc: 0.9048\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0765 - acc: 0.9737\n",
            "Epoch 12: val_loss did not improve from 0.23471\n",
            "63/63 [==============================] - 19s 302ms/step - loss: 0.0765 - acc: 0.9737 - val_loss: 0.9050 - val_acc: 0.7440\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0617 - acc: 0.9841\n",
            "Epoch 13: val_loss did not improve from 0.23471\n",
            "63/63 [==============================] - 19s 305ms/step - loss: 0.0617 - acc: 0.9841 - val_loss: 0.3319 - val_acc: 0.8790\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0488 - acc: 0.9836\n",
            "Epoch 14: val_loss did not improve from 0.23471\n",
            "63/63 [==============================] - 19s 302ms/step - loss: 0.0488 - acc: 0.9836 - val_loss: 0.4678 - val_acc: 0.8552\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0330 - acc: 0.9896\n",
            "Epoch 15: val_loss did not improve from 0.23471\n",
            "63/63 [==============================] - 19s 301ms/step - loss: 0.0330 - acc: 0.9896 - val_loss: 0.2837 - val_acc: 0.8889\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0393 - acc: 0.9901\n",
            "Epoch 16: val_loss did not improve from 0.23471\n",
            "63/63 [==============================] - 19s 303ms/step - loss: 0.0393 - acc: 0.9901 - val_loss: 0.2479 - val_acc: 0.9028\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0373 - acc: 0.9891\n",
            "Epoch 17: val_loss did not improve from 0.23471\n",
            "63/63 [==============================] - 19s 305ms/step - loss: 0.0373 - acc: 0.9891 - val_loss: 0.2796 - val_acc: 0.9107\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0272 - acc: 0.9911\n",
            "Epoch 18: val_loss did not improve from 0.23471\n",
            "63/63 [==============================] - 19s 301ms/step - loss: 0.0272 - acc: 0.9911 - val_loss: 0.5410 - val_acc: 0.7698\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0337 - acc: 0.9906\n",
            "Epoch 19: val_loss did not improve from 0.23471\n",
            "63/63 [==============================] - 19s 305ms/step - loss: 0.0337 - acc: 0.9906 - val_loss: 0.4123 - val_acc: 0.8571\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0329 - acc: 0.9901\n",
            "Epoch 20: val_loss did not improve from 0.23471\n",
            "63/63 [==============================] - 19s 303ms/step - loss: 0.0329 - acc: 0.9901 - val_loss: 0.5137 - val_acc: 0.8135\n",
            "16/16 [==============================] - 4s 225ms/step - loss: 0.2615 - acc: 0.9286\n",
            "[0.2614707052707672, 0.9285714030265808]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this test with increasing difficulty from 1-5\n",
        "# Please note that the weight of the grade for the question is relative\n",
        "# to its difficulty. So your Category 1 question will score much less\n",
        "# than your Category 5 question.\n",
        "# ======================================================================\n",
        "#\n",
        "# Computer Vision with CNNs\n",
        "#\n",
        "# For this task you will build a classifier for Rock-Paper-Scissors \n",
        "# based on the rps dataset.\n",
        "#\n",
        "# IMPORTANT: Your final layer should be as shown, do not change the\n",
        "# provided code, or the tests may fail\n",
        "#\n",
        "# IMPORTANT: Images will be tested as 150x150 with 3 bytes of color depth\n",
        "# So ensure that your input layer is designed accordingly, or the tests\n",
        "# may fail. \n",
        "#\n",
        "# NOTE THAT THIS IS UNLABELLED DATA. \n",
        "# You can use the ImageDataGenerator to automatically label it\n",
        "# and we have provided some starter code.\n",
        "\n",
        "# =========== 합격 기준 가이드라인 공유 ============= #\n",
        "# val_loss 기준에 맞춰 주시는 것이 훨씬 더 중요 #\n",
        "# val_loss 보다 조금 높아도 상관없음. (언저리까지 OK) #\n",
        "# =================================================== #\n",
        "# 문제명: Category 3 - rps\n",
        "# val_loss: 0.0871\n",
        "# val_acc: 0.97\n",
        "# =================================================== #\n",
        "# =================================================== #\n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds \n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def solution_model():\n",
        "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\n",
        "    urllib.request.urlretrieve(url, 'rps.zip')\n",
        "    local_zip = 'rps.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/')\n",
        "    zip_ref.close()\n",
        "\n",
        "    TRAINING_DIR = \"tmp/rps/\"\n",
        "    training_datagen = ImageDataGenerator(\n",
        "        rescale =  1. / 255,   # 픽셀값 조절\n",
        "        rotation_range = 40,    # 이미지 회전\n",
        "        width_shift_range = 0.2,   # 가로 방향 이동\n",
        "        height_shift_range = 0.2,    # 세로 방향 이동\n",
        "        shear_range = 0.2,   # 이미지 굴절\n",
        "        zoom_range = 0.2,    # 이미지 확대\n",
        "        horizontal_flip = True,    # 횡 방향으로 이미지 반전\n",
        "        fill_mode = 'nearest',   # 빈 픽셀값에 대하여 값을 채우는 방식\n",
        "        validation_split = 0.2    # --> train데이터 valid데이터 split\n",
        "    )\n",
        "\n",
        "    train_generator = training_datagen.flow_from_directory(\n",
        "        TRAINING_DIR,\n",
        "        batch_size = 32, \n",
        "        target_size = (150, 150),\n",
        "        class_mode = 'categorical',   # 출력층이 sigmoid인 경우에는 binary로 넣어줘야 함 \n",
        "        subset = 'training',\n",
        "    )\n",
        "\n",
        "    validation_generator = training_datagen.flow_from_directory(\n",
        "        TRAINING_DIR,\n",
        "        batch_size = 32, \n",
        "        target_size = (150, 150), \n",
        "        class_mode = 'categorical', \n",
        "        subset = 'validation',   \n",
        "    )\n",
        "\n",
        "    # 모델 정의\n",
        "    model = Sequential([\n",
        "        Conv2D(128, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n",
        "        MaxPooling2D(2, 2), \n",
        "        Conv2D(128, (3, 3), activation = 'relu'), \n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation = 'relu'), \n",
        "        MaxPooling2D(2, 2), \n",
        "        Conv2D(32, (3, 3), activation = 'relu'), \n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(), \n",
        "        Dropout(0.5), \n",
        "        Dense(512, activation = 'relu'), \n",
        "        Dropout(0.2), \n",
        "        Dense(128, activation = 'relu'), \n",
        "        Dense(32, activation = 'relu'), \n",
        "        Dense(3, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "    # 모델 생성\n",
        "    # IDG는 자동으로 one hot encoding 해줌. \n",
        "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
        "    # optimizer = 'rmsprop'\n",
        "\n",
        "    # 체크포인트 생성\n",
        "    checkpoint_path = 'my_checkpoint_3-rps-3.ckpt'\n",
        "    checkpoint = ModelCheckpoint(filepath = checkpoint_path, \n",
        "                                 save_best_only = True, \n",
        "                                 save_weights_only = True, \n",
        "                                 monitor = 'val_loss', \n",
        "                                 verbose = 1)\n",
        "\n",
        "    # 모델 학습\n",
        "    model.fit(train_generator, \n",
        "          validation_data = (validation_generator), \n",
        "          epochs = 20, \n",
        "          callbacks = [checkpoint])\n",
        "\n",
        "    # best 모델 로드드\n",
        "    model.load_weights(checkpoint_path)\n",
        "\n",
        "    # 모델 검증\n",
        "    print(model.evaluate(validation_generator))  # [0.16, 0.94]\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Note that you'll need to save your model as a .h5 like this\n",
        "# This .h5 will be uploaded to the testing infrastructure\n",
        "# and a score will be returned to you\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"TF3-rps-3.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-r5GZKF-jym",
        "outputId": "ae185dfb-e7b9-44bd-e7f2-cc9e381876b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2016 images belonging to 3 classes.\n",
            "Found 504 images belonging to 3 classes.\n",
            "Epoch 1/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.1023 - acc: 0.3512\n",
            "Epoch 1: val_loss improved from inf to 1.09760, saving model to my_checkpoint_3-rps-3.ckpt\n",
            "63/63 [==============================] - 22s 322ms/step - loss: 1.1023 - acc: 0.3512 - val_loss: 1.0976 - val_acc: 0.3333\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.0793 - acc: 0.3919\n",
            "Epoch 2: val_loss improved from 1.09760 to 1.01717, saving model to my_checkpoint_3-rps-3.ckpt\n",
            "63/63 [==============================] - 20s 314ms/step - loss: 1.0793 - acc: 0.3919 - val_loss: 1.0172 - val_acc: 0.5278\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.7577 - acc: 0.6553\n",
            "Epoch 3: val_loss improved from 1.01717 to 0.85929, saving model to my_checkpoint_3-rps-3.ckpt\n",
            "63/63 [==============================] - 20s 320ms/step - loss: 0.7577 - acc: 0.6553 - val_loss: 0.8593 - val_acc: 0.5298\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.5182 - acc: 0.7897\n",
            "Epoch 4: val_loss improved from 0.85929 to 0.72893, saving model to my_checkpoint_3-rps-3.ckpt\n",
            "63/63 [==============================] - 20s 313ms/step - loss: 0.5182 - acc: 0.7897 - val_loss: 0.7289 - val_acc: 0.6944\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3161 - acc: 0.8800\n",
            "Epoch 5: val_loss did not improve from 0.72893\n",
            "63/63 [==============================] - 19s 308ms/step - loss: 0.3161 - acc: 0.8800 - val_loss: 0.7451 - val_acc: 0.6687\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2498 - acc: 0.9092\n",
            "Epoch 6: val_loss improved from 0.72893 to 0.55192, saving model to my_checkpoint_3-rps-3.ckpt\n",
            "63/63 [==============================] - 20s 315ms/step - loss: 0.2498 - acc: 0.9092 - val_loss: 0.5519 - val_acc: 0.7540\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1703 - acc: 0.9355\n",
            "Epoch 7: val_loss did not improve from 0.55192\n",
            "63/63 [==============================] - 20s 316ms/step - loss: 0.1703 - acc: 0.9355 - val_loss: 0.7314 - val_acc: 0.7242\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2001 - acc: 0.9315\n",
            "Epoch 8: val_loss did not improve from 0.55192\n",
            "63/63 [==============================] - 20s 313ms/step - loss: 0.2001 - acc: 0.9315 - val_loss: 0.9720 - val_acc: 0.5734\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2021 - acc: 0.9201\n",
            "Epoch 9: val_loss improved from 0.55192 to 0.52853, saving model to my_checkpoint_3-rps-3.ckpt\n",
            "63/63 [==============================] - 20s 314ms/step - loss: 0.2021 - acc: 0.9201 - val_loss: 0.5285 - val_acc: 0.8274\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1562 - acc: 0.9454\n",
            "Epoch 10: val_loss did not improve from 0.52853\n",
            "63/63 [==============================] - 20s 312ms/step - loss: 0.1562 - acc: 0.9454 - val_loss: 1.1246 - val_acc: 0.6230\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1196 - acc: 0.9578\n",
            "Epoch 11: val_loss did not improve from 0.52853\n",
            "63/63 [==============================] - 20s 312ms/step - loss: 0.1196 - acc: 0.9578 - val_loss: 0.5400 - val_acc: 0.7877\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1050 - acc: 0.9658\n",
            "Epoch 12: val_loss did not improve from 0.52853\n",
            "63/63 [==============================] - 20s 312ms/step - loss: 0.1050 - acc: 0.9658 - val_loss: 0.6700 - val_acc: 0.7480\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1149 - acc: 0.9623\n",
            "Epoch 13: val_loss did not improve from 0.52853\n",
            "63/63 [==============================] - 20s 318ms/step - loss: 0.1149 - acc: 0.9623 - val_loss: 0.6661 - val_acc: 0.7202\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0995 - acc: 0.9668\n",
            "Epoch 14: val_loss did not improve from 0.52853\n",
            "63/63 [==============================] - 20s 317ms/step - loss: 0.0995 - acc: 0.9668 - val_loss: 1.4642 - val_acc: 0.6151\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0964 - acc: 0.9623\n",
            "Epoch 15: val_loss improved from 0.52853 to 0.48963, saving model to my_checkpoint_3-rps-3.ckpt\n",
            "63/63 [==============================] - 20s 319ms/step - loss: 0.0964 - acc: 0.9623 - val_loss: 0.4896 - val_acc: 0.8036\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.1270 - acc: 0.9554\n",
            "Epoch 16: val_loss did not improve from 0.48963\n",
            "63/63 [==============================] - 20s 314ms/step - loss: 0.1270 - acc: 0.9554 - val_loss: 1.1978 - val_acc: 0.6210\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0897 - acc: 0.9688\n",
            "Epoch 17: val_loss did not improve from 0.48963\n",
            "63/63 [==============================] - 20s 313ms/step - loss: 0.0897 - acc: 0.9688 - val_loss: 0.5318 - val_acc: 0.7976\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0797 - acc: 0.9702\n",
            "Epoch 18: val_loss improved from 0.48963 to 0.33838, saving model to my_checkpoint_3-rps-3.ckpt\n",
            "63/63 [==============================] - 20s 319ms/step - loss: 0.0797 - acc: 0.9702 - val_loss: 0.3384 - val_acc: 0.8690\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0697 - acc: 0.9772\n",
            "Epoch 19: val_loss did not improve from 0.33838\n",
            "63/63 [==============================] - 20s 311ms/step - loss: 0.0697 - acc: 0.9772 - val_loss: 0.7409 - val_acc: 0.6806\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.0935 - acc: 0.9668\n",
            "Epoch 20: val_loss did not improve from 0.33838\n",
            "63/63 [==============================] - 20s 311ms/step - loss: 0.0935 - acc: 0.9668 - val_loss: 0.7479 - val_acc: 0.6925\n",
            "16/16 [==============================] - 4s 230ms/step - loss: 0.3795 - acc: 0.8532\n",
            "[0.3794626295566559, 0.85317462682724]\n"
          ]
        }
      ]
    }
  ]
}